{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.base import clone\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, cohen_kappa_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the datasets\n",
    "train_file_path = \"train_values_impute.csv\"\n",
    "train_df = pd.read_csv(train_file_path)\n",
    "test_file_path = \"test_values_impute.csv\"\n",
    "test_df = pd.read_csv(test_file_path)\n",
    "df = train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA EXPLORATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ft = train_df.copy()\n",
    "test_ft = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_max_min_col(df):\n",
    "    df['GS_max'] = df[['FGC-FGC_GSND', 'FGC-FGC_GSD']].max(axis=1)\n",
    "    df['GS_min'] = df[['FGC-FGC_GSND', 'FGC-FGC_GSD']].min(axis=1)\n",
    "\n",
    "    df[\"SR_min\"] = df[['FGC-FGC_SRL', 'FGC-FGC_SRR']].min(axis=1)\n",
    "    df[\"SR_max\"] = df[['FGC-FGC_SRL', 'FGC-FGC_SRR']].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_new_max_min_col(train_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_new_max_min_col(test_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [5, 10, 15, 18, 22]\n",
    "cu_map = {}\n",
    "pu_map = {}\n",
    "tl_map = {}\n",
    "gs_max_map = {}\n",
    "gs_min_map = {}\n",
    "bmr_map = {}\n",
    "dee_map = {}\n",
    "sr_min_map = {}\n",
    "sr_max_map = {}\n",
    "ffmi_map = {}\n",
    "\n",
    "\n",
    "prev = 0\n",
    "for i in range(len(thresholds)):\n",
    "    curr = thresholds[i]\n",
    "    mean_cu = train_ft[(train_ft['Basic_Demos-Age'] > prev) & (train_ft['Basic_Demos-Age'] <= curr)]['FGC-FGC_CU'].mean()\n",
    "    mean_pu = train_ft[(train_ft['Basic_Demos-Age'] > prev) & (train_ft['Basic_Demos-Age'] <= curr)]['FGC-FGC_PU'].mean()\n",
    "    mean_tl = train_ft[(train_ft['Basic_Demos-Age'] > prev) & (train_ft['Basic_Demos-Age'] <= curr)]['FGC-FGC_TL'].mean()\n",
    "    mean_gs_max = train_ft[(train_ft['Basic_Demos-Age'] > prev) & (train_ft['Basic_Demos-Age'] <= curr)]['GS_max'].mean()\n",
    "    mean_gs_min = train_ft[(train_ft['Basic_Demos-Age'] > prev) & (train_ft['Basic_Demos-Age'] <= curr)]['GS_min'].mean()\n",
    "    mean_bmr = train_ft[(train_ft['Basic_Demos-Age'] > prev) & (train_ft['Basic_Demos-Age'] <= curr)]['BIA-BIA_BMR'].mean()\n",
    "    mean_dee = train_ft[(train_ft['Basic_Demos-Age'] > prev) & (train_ft['Basic_Demos-Age'] <= curr)]['BIA-BIA_DEE'].mean()\n",
    "    mean_sr_min = train_ft[(train_ft['Basic_Demos-Age'] > prev) & (train_ft['Basic_Demos-Age'] <= curr)]['SR_min'].mean()\n",
    "    mean_sr_max = train_ft[(train_ft['Basic_Demos-Age'] > prev) & (train_ft['Basic_Demos-Age'] <= curr)]['SR_max'].mean()\n",
    "    mean_ffmi = train_ft[(train_ft['Basic_Demos-Age'] > prev) & (train_ft['Basic_Demos-Age'] <= curr)]['BIA-BIA_FFMI'].mean()\n",
    "    cu_map[i] = mean_cu\n",
    "    pu_map[i] = mean_pu\n",
    "    tl_map[i] = mean_tl\n",
    "    gs_max_map[i] = mean_gs_max\n",
    "    gs_min_map[i] = mean_gs_min\n",
    "    bmr_map[i] = mean_bmr\n",
    "    dee_map[i] = mean_dee\n",
    "    sr_min_map[i] = mean_sr_min\n",
    "    sr_max_map[i] = mean_sr_max\n",
    "    ffmi_map[i] = mean_ffmi\n",
    "    \n",
    "    prev = curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cu_map:  {0: 1.4894075826009996, 1: 7.476433412668704, 2: 16.73709242262834, 3: 21.407771986194827, 4: 25.30853654685808}\n",
      "pu_map:  {0: 1.6124985934130887, 1: 4.5169419747697965, 2: 6.784395686334561, 3: 8.478444895075162, 4: 6.821968965779475}\n",
      "tl_map:  {0: 8.120492018715137, 1: 8.869554898368646, 2: 9.838626506051705, 3: 9.917901720651995, 4: 9.692428580093807}\n",
      "gs_max_map {0: 3.9099297688947945, 1: 10.55672195840937, 2: 23.292464861164753, 3: 32.78846762533555, 4: 38.36685722870873}\n",
      "gs_min_map {0: 2.736800716173679, 1: 10.002960767347604, 2: 21.30362495880886, 3: 29.72703462536007, 4: 35.603563385045724}\n",
      "bmr_map {0: 923.5225434249359, 1: 1044.0911206823437, 2: 1349.4340136900846, 3: 1570.3551673344439, 4: 1600.771724721695}\n",
      "dee_map {0: 1482.2122961876526, 1: 1727.4929346670194, 2: 2287.120935391911, 3: 2659.7318780880137, 4: 2689.29223414726}\n",
      "sr_min_map {0: 9.096963629930148, 1: 8.625937676320195, 2: 8.155678517119915, 3: 8.436815249729667, 4: 8.8197600575827}\n",
      "sr_max_map {0: 9.875571772620813, 1: 9.231811410987419, 2: 8.754870407983, 3: 9.083542060238827, 4: 8.988572460857961}\n",
      "ffmi_map {0: 14.629390452362466, 1: 14.377788378958094, 2: 15.619324380061393, 3: 16.426951513808, 4: 16.711070808672822}\n"
     ]
    }
   ],
   "source": [
    "print(\"cu_map: \", cu_map)\n",
    "print(\"pu_map: \", pu_map)\n",
    "print(\"tl_map: \", tl_map)\n",
    "print(\"gs_max_map\", gs_max_map)\n",
    "print(\"gs_min_map\", gs_min_map)\n",
    "print(\"bmr_map\", bmr_map)\n",
    "print(\"dee_map\", dee_map)\n",
    "print(\"sr_min_map\", sr_min_map)\n",
    "print(\"sr_max_map\", sr_max_map)\n",
    "print(\"ffmi_map\", ffmi_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_data(train, test, columns, n_bins=10):\n",
    "    # Combine train and test for consistent bin edges\n",
    "    combined = pd.concat([train, test], axis=0)\n",
    "\n",
    "    bin_edges = {}\n",
    "    for col in columns:\n",
    "        # Compute quantile bin edges correctly\n",
    "        edges = pd.qcut(combined[col], n_bins, retbins=True, labels=False, duplicates=\"drop\")[1]\n",
    "        bin_edges[col] = edges\n",
    "\n",
    "    # Apply the same bin edges to both train and test\n",
    "    for col, edges in bin_edges.items():\n",
    "        num_bins = len(edges) - 1  # Ensure the correct number of labels\n",
    "        labels = range(num_bins)   # Matching labels with bins\n",
    "\n",
    "        train[col] = pd.cut(train[col], bins=edges, labels=labels, include_lowest=True).astype(float)\n",
    "        test[col] = pd.cut(test[col], bins=edges, labels=labels, include_lowest=True).astype(float)\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "\n",
    "    df[\"CU_norm\"] = df['FGC-FGC_CU'] / df['age_group'].map(cu_map)\n",
    "    df[\"PU_norm\"] = df['FGC-FGC_PU'] / df['age_group'].map(pu_map)\n",
    "    df[\"TL_norm\"] = df['FGC-FGC_TL'] / df['age_group'].map(tl_map)\n",
    "\n",
    "    df['GS_max_norm'] = df['GS_max'] / df[\"age_group\"].map(gs_max_map)\n",
    "    df['GS_min_norm'] = df['GS_min'] / df[\"age_group\"].map(gs_min_map)\n",
    "\n",
    "    df['SR_max_norm'] = df['SR_max'] / df[\"age_group\"].map(gs_max_map)\n",
    "    df['SR_min_norm'] = df['SR_min'] / df[\"age_group\"].map(gs_min_map)\n",
    "\n",
    "    df[\"BMR_norm\"] = df[\"BIA-BIA_BMR\"] / df[\"age_group\"].map(bmr_map)\n",
    "    df[\"DEE_norm\"] = df[\"BIA-BIA_DEE\"] / df[\"age_group\"].map(dee_map)\n",
    "\n",
    "    df[\"FFMI_norm\"] = df[\"BIA-BIA_FFMI\"] / df[\"age_group\"].map(ffmi_map)\n",
    "\n",
    "    df[\"ECW_ICW_ratio\"] = df[\"BIA-BIA_ECW\"] / df[\"BIA-BIA_ICW\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_bin = [\n",
    "    \"CU_norm\", \"PU_norm\", \"TL_norm\", \"GS_min_norm\", \"GS_max_norm\", \n",
    "    \"SR_min_norm\", \"SR_max_norm\", \"BMR_norm\", \"DEE_norm\", \"FFMI_norm\", \"Physical-HeartRate\", \"Physical-Waist_Circumference\", \"Physical-Height\" ,\"Physical-Weight\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'BIA-BIA_BMI' already removed, so no need to add here\n",
    "columns_to_remove = ['FGC-FGC_CU', 'FGC-FGC_GSND', 'FGC-FGC_GSD', 'FGC-FGC_PU', 'FGC-FGC_SRL', 'FGC-FGC_SRR', 'FGC-FGC_TL', \n",
    "                    'BIA-BIA_FFM', 'BIA-BIA_FMI','BIA-BIA_Frame_num', 'BIA-BIA_LDM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_engineering(train_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_engineering(test_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ft, test_ft = bin_data(train_ft, test_ft, columns_to_bin, n_bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ft = train_ft.drop(columns_to_remove, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ft = test_ft.drop(columns_to_remove, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3960, 79)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ft.to_csv(\"train_ft.csv\", index=False)\n",
    "test_ft.to_csv(\"test_ft.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
