{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.base import clone\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, cohen_kappa_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import optuna\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the datasets\n",
    "train_file_path = \"train_ft.csv\"\n",
    "train = pd.read_csv(train_file_path)\n",
    "test_file_path = \"test_ft.csv\"\n",
    "test = pd.read_csv(test_file_path)\n",
    "df = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dropna(subset=['sii'], how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sii_thresholds = [30, 50, 80, 100] # Thresholds for rating\n",
    "def get_rating(x): ## Thresholds for rating\n",
    "    if 0 <= x <= 29:\n",
    "        return 0\n",
    "    elif 30 <= x <= 49:\n",
    "        return 1\n",
    "    elif 50 <= x <= 79:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "def quadratic_weighted_kappa(y_true, y_pred): # The Quadric Kappa Evaluation Metric\n",
    "    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "\n",
    "def evaluate_predictions(y_true, oof_non_rounded):\n",
    "    rounded_p = get_rating(oof_non_rounded)\n",
    "    return -quadratic_weighted_kappa(y_true, rounded_p)\n",
    "\n",
    "#train_impute_lr['new_sii'] = train_impute_lr['PCIAT_Total_Imputed'].apply(get_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    if train[col].dtype == 'object' or str(train[col].dtype) == 'category':\n",
    "        le = LabelEncoder()\n",
    "        train[col] = le.fit_transform(train[col].astype(str))\n",
    "\n",
    "for col in test.columns:\n",
    "    if test[col].dtype == 'object' or str(test[col].dtype) == 'category':\n",
    "        le = LabelEncoder()\n",
    "        test[col] = le.fit_transform(test[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = train\n",
    "Y_target = train['PCIAT-PCIAT_Total']\n",
    "X = train_model.drop(columns=['id', 'sii', 'PCIAT-PCIAT_01', 'PCIAT-PCIAT_02', 'PCIAT-PCIAT_03','PCIAT-PCIAT_04', 'PCIAT-PCIAT_05', 'PCIAT-PCIAT_06', 'PCIAT-PCIAT_07',\n",
    "           'PCIAT-PCIAT_08', 'PCIAT-PCIAT_09', 'PCIAT-PCIAT_10', 'PCIAT-PCIAT_11',\n",
    "           'PCIAT-PCIAT_12', 'PCIAT-PCIAT_13', 'PCIAT-PCIAT_14', 'PCIAT-PCIAT_15',\n",
    "           'PCIAT-PCIAT_16', 'PCIAT-PCIAT_17', 'PCIAT-PCIAT_18', 'PCIAT-PCIAT_19',\n",
    "           'PCIAT-PCIAT_20', 'PCIAT-PCIAT_Total'])\n",
    "Y_class = train['sii']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BALANCING THE DATASET (UPSAMPLING AND DOWNSAMPLING IS NOT APPROPRIATE FOR THIS DATASET)\n",
    "def sample_weights_optimized(series):\n",
    "    \"\"\"\n",
    "    Calculate sample weights for continuous PCIAT target variables using equal-width binning to solve class imbalance issue by finding frequency of each pciat total value: Converts frequency into weight:\n",
    "    Rare bins get higher weights (inverse of frequency is used to calculate weight )\n",
    "    Common bins get lower weights\n",
    "  \n",
    "    \n",
    "    Parameters:\n",
    "    series: pandas Series containing all target values (assumed continuous with no nulls)\n",
    "    \n",
    "    Returns:\n",
    "    pandas Series: Sample weights normalized to mean 1.0\n",
    "    \"\"\"\n",
    "    # Handle edge cases efficiently\n",
    "    if len(series) <= 1 or series.nunique() <= 1:\n",
    "        return pd.Series(1.0, index=series.index)\n",
    "    \n",
    "    # Create equal-width bins directly\n",
    "    bins = pd.cut(series, bins=10, labels=False)\n",
    "    \n",
    "    # Get bin counts and calculate inverse frequency in one step\n",
    "    bin_counts = bins.value_counts()\n",
    "    inverse_freq = 1.0 / bin_counts\n",
    "    \n",
    "    # Map weights back to samples using the bin indices\n",
    "    weights = bins.map(inverse_freq)\n",
    "    \n",
    "    # Normalize weights to mean 1.0\n",
    "    return weights / weights.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_categories(predictions, boundary_values):\n",
    "    \"\"\"\n",
    "    Transform continuous prediction values into discrete categories \n",
    "    based on specified boundary thresholds.\n",
    "    \"\"\"\n",
    "    categories = np.zeros(len(predictions), dtype=int)\n",
    "    \n",
    "    # Apply each threshold sequentially\n",
    "    for category, threshold in enumerate(boundary_values):\n",
    "        categories[predictions >= threshold] = category + 1\n",
    "        \n",
    "    return categories\n",
    "\n",
    "\n",
    "def find_optimal_boundaries(actual_values, model_predictions, initial_boundaries=None):\n",
    "    \"\"\"\n",
    "    Determine the optimal category boundaries that maximize agreement\n",
    "    between predictions and actual values using quadratic weighted kappa.\n",
    "    \"\"\"\n",
    "    # Set default initial boundaries if none provided\n",
    "    if initial_boundaries is None:\n",
    "        initial_boundaries = [0.5, 1.5, 2.5]\n",
    "    \n",
    "    # Define optimization objective function\n",
    "    def objective_function(boundaries, actuals, predictions):\n",
    "        categorized_predictions = convert_to_categories(predictions, boundaries)\n",
    "        kappa_score = cohen_kappa_score(actuals, categorized_predictions, weights='quadratic')\n",
    "        # Return negative since we want to maximize kappa\n",
    "        return -kappa_score\n",
    "    \n",
    "    # Perform optimization\n",
    "    optimization_result = minimize(\n",
    "        objective_function, \n",
    "        x0=initial_boundaries,\n",
    "        args=(actual_values, model_predictions),\n",
    "        method='Powell'\n",
    "    )\n",
    "    \n",
    "    # Verify optimization completed successfully\n",
    "    if not optimization_result.success:\n",
    "        raise RuntimeError(\"Boundary optimization failed to converge\")\n",
    "        \n",
    "    return optimization_result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_k_fold_validate(estimator, dataset, target_col, class_col, splitter, apply_weighting=False, show_progress=False):\n",
    "   \"\"\"\n",
    "   Evaluates a model using k-fold validation, optimizing decision boundaries to maximize agreement.\n",
    "   \n",
    "   Parameters:\n",
    "   - estimator: Model object with fit and predict methods\n",
    "   - dataset: DataFrame containing all data\n",
    "   - predictors: List of feature column names\n",
    "   - target_col: Column name for continuous target variable\n",
    "   - class_col: Column name for class labels\n",
    "   - splitter: Cross-validation iterator\n",
    "   - apply_weighting: Whether to apply balancing weights during training\n",
    "   - show_progress: Whether to display progress information\n",
    "   \n",
    "   Returns:\n",
    "   - mean_agreement: Average kappa agreement score across folds\n",
    "   - holdout_predictions: Predictions for all samples from their respective holdout folds\n",
    "   - boundary_sets: Optimized decision boundaries from each fold\n",
    "   \"\"\"\n",
    "   agreement_metrics = []\n",
    "   holdout_predictions = np.zeros(dataset.shape[0])\n",
    "   boundary_sets = []\n",
    "   \n",
    "   # Default decision boundaries if needed\n",
    "   default_boundaries = sii_thresholds\n",
    "   \n",
    "   # Iterate through cross-validation folds\n",
    "   for fold_num, (training_indices, validation_indices) in enumerate(splitter.split(dataset, class_col)):\n",
    "       # Extract training and validation data\n",
    "       X_training = dataset.iloc[training_indices]\n",
    "       y_training_target = target_col.iloc[training_indices] ## PCIAT Total\n",
    "       y_training_class = class_col.iloc[training_indices] ## SII\n",
    "       \n",
    "       X_validation = dataset.iloc[validation_indices]\n",
    "       y_validation_target = target_col.iloc[validation_indices]  ## PCIAT Total\n",
    "       y_validation_class = class_col.iloc[validation_indices] ## SIIs\n",
    "\n",
    "       # # Remove the 'id' column from your training data\n",
    "       # X_training = X_training.drop(columns=['id'])\n",
    "       # X_validation = X_validation.drop(columns=['id'])\n",
    "       \n",
    "       # Apply sample weighting if needed for class imbalance issue \n",
    "       if apply_weighting:\n",
    "           sample_weights = sample_weights_optimized(y_training_target)\n",
    "           estimator.fit(X_training, y_training_target, sample_weight=sample_weights)\n",
    "       else:\n",
    "           estimator.fit(X_training, y_training_target)\n",
    "       \n",
    "       # Generate predictions\n",
    "       training_predictions = estimator.predict(X_training)\n",
    "       validation_predictions = estimator.predict(X_validation)\n",
    "       \n",
    "       # Store predictions in the appropriate positions\n",
    "       holdout_predictions[validation_indices] = validation_predictions\n",
    "       \n",
    "       # Optimize decision boundaries based on training predictions\n",
    "       optimized_boundaries = find_optimal_boundaries(\n",
    "           y_training_class, \n",
    "           training_predictions, \n",
    "           initial_boundaries=default_boundaries\n",
    "       )\n",
    "       boundary_sets.append(optimized_boundaries)\n",
    "       \n",
    "       # Apply optimized boundaries to validation predictions\n",
    "       discretized_predictions = convert_to_categories(validation_predictions, optimized_boundaries)\n",
    "       \n",
    "       # Calculate kappa metric\n",
    "       kappa = cohen_kappa_score(y_validation_class, discretized_predictions, weights='quadratic')\n",
    "       agreement_metrics.append(kappa)\n",
    "       # \n",
    "       if show_progress:\n",
    "           print(f\"Fold {fold_num+1}: Quadratic Kappa = {kappa:.4f}\")\n",
    "   \n",
    "   if show_progress:\n",
    "       print(f\"Mean Agreement: {np.mean(agreement_metrics):.4f}\")\n",
    "       print(f\"Standard Deviation: {np.std(agreement_metrics):.4f}\")\n",
    "   \n",
    "   return np.mean(agreement_metrics), holdout_predictions, boundary_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_xgb(trial, dataset, target_col, class_col,splitter, apply_weighting):\n",
    "    \"\"\"\n",
    "    Optuna objective function for XGBoost parameter optimization.\n",
    "    \n",
    "    Parameters:\n",
    "    trial: Optuna trial object\n",
    "    X: Features DataFrame\n",
    "    y: Target Series\n",
    "    eval_metric: Metric to evaluate on\n",
    "    \n",
    "    Returns:\n",
    "    float: Mean cross-validation score (RMSE)\n",
    "    \"\"\"\n",
    "    # Parameter search space definition\n",
    "    params = {\n",
    "        'objective': trial.suggest_categorical('objective', ['reg:squarederror', 'reg:tweedie']),\n",
    "        'tree_method': 'approx',\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 6),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 0.9),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 0.9),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-5, 0.1),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-5, 0.1),\n",
    "        'random_state': 42,\n",
    "        'verbosity': 0\n",
    "    }\n",
    "    \n",
    "    # Add tweedie-specific parameters if that objective is selected\n",
    "    if params['objective'] == 'reg:tweedie':\n",
    "        params['tweedie_variance_power'] = trial.suggest_float('tweedie_variance_power', 1.0, 2.0)\n",
    "    \n",
    "    model = XGBRegressor(**params)\n",
    "    score, _, _ = evaluate_k_fold_validate(\n",
    "        estimator=model,\n",
    "        dataset=dataset,\n",
    "        target_col=target_col,\n",
    "        class_col=class_col,\n",
    "        splitter=splitter,\n",
    "        apply_weighting=apply_weighting,\n",
    "        show_progress=False\n",
    "    )\n",
    "    return score\n",
    "\n",
    "\n",
    "def optimize_lgbm(trial, dataset, target_col, class_col, splitter, apply_weighting):\n",
    "    params = {\n",
    "        'objective': trial.suggest_categorical('objective', ['regression', 'poisson', 'tweedie']),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 6),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 0.9),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 0.9),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n",
    "        'random_state': 42,\n",
    "        'verbosity': -1\n",
    "    }\n",
    "\n",
    "    if params['objective'] == 'tweedie':\n",
    "        params['tweedie_variance_power'] = trial.suggest_float('tweedie_variance_power', 1.0, 2.0)\n",
    "\n",
    "    model = LGBMRegressor(**params)\n",
    "    score, _, _ = evaluate_k_fold_validate(\n",
    "        estimator=model,\n",
    "        dataset=dataset,\n",
    "        target_col=target_col,\n",
    "        class_col=class_col,\n",
    "        splitter=splitter,\n",
    "        apply_weighting=apply_weighting,\n",
    "        show_progress=False\n",
    "    )\n",
    "    return score\n",
    "\n",
    "\n",
    "def optimize_extraTrees(trial, dataset, target_col, class_col, splitter, apply_weighting):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 30),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
    "        'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    model = ExtraTreesRegressor(**params)\n",
    "    score, _, _ = evaluate_k_fold_validate(\n",
    "        estimator=model,\n",
    "        dataset=dataset,\n",
    "        target_col=target_col,\n",
    "        class_col=class_col,\n",
    "        splitter=splitter,\n",
    "        apply_weighting=apply_weighting,\n",
    "        show_progress=False\n",
    "    )\n",
    "    return score\n",
    "\n",
    "def optimize_catboost(trial, dataset, target_col, class_col, splitter, apply_weighting):\n",
    "    params = {\n",
    "        'loss_function': trial.suggest_categorical('loss_function', ['RMSE', 'Poisson']),\n",
    "        'iterations': trial.suggest_int('iterations', 100, 300),\n",
    "        'depth': trial.suggest_int('depth', 3, 7),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-3, 0.1),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
    "        'random_strength': trial.suggest_float('random_strength', 1e-3, 10.0),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 20, 60),\n",
    "        'random_seed': 42,\n",
    "        'verbose': 0\n",
    "    }\n",
    "\n",
    "    model = CatBoostRegressor(**params)\n",
    "    score, _, _ = evaluate_k_fold_validate(\n",
    "        estimator=model,\n",
    "        dataset=dataset,\n",
    "        target_col=target_col,\n",
    "        class_col=class_col,\n",
    "        splitter=splitter,\n",
    "        apply_weighting=apply_weighting,\n",
    "        show_progress=False\n",
    "    )\n",
    "    return score\n",
    "    \n",
    "\n",
    "def run_optuna_optimization(dataset, target_col, class_col, model_type, splitter, apply_weighting=True, n_trials=30):\n",
    "    \"\"\"\n",
    "    Run Optuna optimization for the specified model type.\n",
    "    \n",
    "    Parameters:\n",
    "    X: Features DataFrame\n",
    "    y: Target Series\n",
    "    model_type: Type of model to optimize ('xgb', 'lgbm', or 'catboost')\n",
    "    n_trials: Number of optimization trials\n",
    "    \n",
    "    Returns:\n",
    "    dict: Best parameters found by Optuna\n",
    "    \"\"\"\n",
    "    print(f\"Starting optimization for {model_type.upper()} with {n_trials} trials\")\n",
    "    \n",
    "    # Create Optuna study (set direction to minimize for RMSE)\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    \n",
    "    # Select the appropriate objective function\n",
    "    if model_type.lower() == 'xgb':\n",
    "        study.optimize(lambda trial: optimize_xgb(trial, dataset, target_col, class_col, splitter, apply_weighting),\n",
    "                   n_trials=n_trials)\n",
    "    elif model_type.lower() == 'lgbm':\n",
    "        study.optimize(lambda trial: optimize_lgbm(trial, dataset, target_col, class_col, splitter, apply_weighting),\n",
    "                   n_trials=n_trials)\n",
    "    elif model_type.lower() == 'extratrees':\n",
    "        study.optimize(lambda trial: optimize_extraTrees(trial, dataset, target_col, class_col, splitter, apply_weighting),\n",
    "                   n_trials=n_trials)\n",
    "    elif model_type.lower() == 'catboost':\n",
    "        study.optimize(lambda trial: optimize_xgb(trial, dataset, target_col, class_col, splitter, apply_weighting),\n",
    "                   n_trials=n_trials)\n",
    "    else:\n",
    "        raise ValueError(\"model_type must be 'xgb', 'lgbm', 'catboost' or 'extratrees'\")\n",
    "    \n",
    "    print(\"\\nBest Parameters:\")\n",
    "    print(study.best_params)\n",
    "    print(f\"Best Quadratic Kappa: {study.best_value:.4f}\")\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-17 22:03:39,990] A new study created in memory with name: no-name-39398760-8958-40e2-9b31-9f078c77ed7a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting optimization for XGB with 30 trials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-17 22:03:46,170] Trial 0 finished with value: 0.9944540166555506 and parameters: {'objective': 'reg:tweedie', 'n_estimators': 214, 'max_depth': 5, 'learning_rate': 0.058131242366271714, 'subsample': 0.8350136284893762, 'colsample_bytree': 0.8425491436287053, 'reg_alpha': 0.008320724359235128, 'reg_lambda': 0.0004251631484097355, 'tweedie_variance_power': 1.8880546620140883}. Best is trial 0 with value: 0.9944540166555506.\n",
      "[I 2025-04-17 22:03:49,998] Trial 1 finished with value: 0.9932235702390001 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 296, 'max_depth': 5, 'learning_rate': 0.051381152682945706, 'subsample': 0.7045204257835828, 'colsample_bytree': 0.7190558659684394, 'reg_alpha': 0.09069581793382966, 'reg_lambda': 0.09474529207531625}. Best is trial 0 with value: 0.9944540166555506.\n",
      "[I 2025-04-17 22:03:54,005] Trial 2 finished with value: 0.9728698963413297 and parameters: {'objective': 'reg:tweedie', 'n_estimators': 255, 'max_depth': 2, 'learning_rate': 0.011130997290418446, 'subsample': 0.8283112447715977, 'colsample_bytree': 0.687656725338414, 'reg_alpha': 0.0027379248337069504, 'reg_lambda': 0.05725058504349552, 'tweedie_variance_power': 1.848854894031465}. Best is trial 0 with value: 0.9944540166555506.\n",
      "[I 2025-04-17 22:03:57,094] Trial 3 finished with value: 0.9882906472765086 and parameters: {'objective': 'reg:tweedie', 'n_estimators': 178, 'max_depth': 2, 'learning_rate': 0.03275442225870532, 'subsample': 0.596975603663592, 'colsample_bytree': 0.6619610645284357, 'reg_alpha': 0.06852985122621578, 'reg_lambda': 0.09323134242223681, 'tweedie_variance_power': 1.1818107755948954}. Best is trial 0 with value: 0.9944540166555506.\n",
      "[I 2025-04-17 22:04:02,755] Trial 4 finished with value: 0.9887810076351743 and parameters: {'objective': 'reg:tweedie', 'n_estimators': 280, 'max_depth': 4, 'learning_rate': 0.05749955728955031, 'subsample': 0.7728699389471789, 'colsample_bytree': 0.8022968165291509, 'reg_alpha': 0.05885620793781231, 'reg_lambda': 0.053026488500437265, 'tweedie_variance_power': 1.4818591298545072}. Best is trial 0 with value: 0.9944540166555506.\n",
      "[I 2025-04-17 22:04:04,322] Trial 5 finished with value: 0.9923216353310998 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 109, 'max_depth': 3, 'learning_rate': 0.0507254372283283, 'subsample': 0.8791040154198669, 'colsample_bytree': 0.7704621913869619, 'reg_alpha': 0.03418935898589341, 'reg_lambda': 0.059524226841352286}. Best is trial 0 with value: 0.9944540166555506.\n",
      "[I 2025-04-17 22:04:09,595] Trial 6 finished with value: 0.9971461219085643 and parameters: {'objective': 'reg:tweedie', 'n_estimators': 149, 'max_depth': 6, 'learning_rate': 0.011373910578413733, 'subsample': 0.6571800359504983, 'colsample_bytree': 0.8112703136782964, 'reg_alpha': 0.0648634316904529, 'reg_lambda': 0.05919209331740932, 'tweedie_variance_power': 1.589253184926814}. Best is trial 6 with value: 0.9971461219085643.\n",
      "[I 2025-04-17 22:04:13,241] Trial 7 finished with value: 0.9806708556236152 and parameters: {'objective': 'reg:tweedie', 'n_estimators': 194, 'max_depth': 3, 'learning_rate': 0.03813624183193479, 'subsample': 0.6168081276716822, 'colsample_bytree': 0.5703567986629905, 'reg_alpha': 0.07021515265382094, 'reg_lambda': 0.033030338406567286, 'tweedie_variance_power': 1.8621310900457582}. Best is trial 6 with value: 0.9971461219085643.\n",
      "[I 2025-04-17 22:04:17,662] Trial 8 finished with value: 0.9720590201404347 and parameters: {'objective': 'reg:tweedie', 'n_estimators': 222, 'max_depth': 3, 'learning_rate': 0.07466555237550625, 'subsample': 0.7274963282054258, 'colsample_bytree': 0.6156723072082186, 'reg_alpha': 0.06972536318334507, 'reg_lambda': 0.06033712310194583, 'tweedie_variance_power': 1.7618918949393478}. Best is trial 6 with value: 0.9971461219085643.\n",
      "[I 2025-04-17 22:04:20,985] Trial 9 finished with value: 0.9914054570489229 and parameters: {'objective': 'reg:tweedie', 'n_estimators': 116, 'max_depth': 5, 'learning_rate': 0.09572118094255352, 'subsample': 0.5729441346841487, 'colsample_bytree': 0.7993180865613067, 'reg_alpha': 0.07323590321850151, 'reg_lambda': 0.09026592802330066, 'tweedie_variance_power': 1.3000458053990587}. Best is trial 6 with value: 0.9971461219085643.\n",
      "[I 2025-04-17 22:04:24,187] Trial 10 finished with value: 1.0 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 153, 'max_depth': 6, 'learning_rate': 0.013769795623498312, 'subsample': 0.5036259961123959, 'colsample_bytree': 0.8990403873185487, 'reg_alpha': 0.03718980808445292, 'reg_lambda': 0.02905102865197595}. Best is trial 10 with value: 1.0.\n",
      "[I 2025-04-17 22:04:27,149] Trial 11 finished with value: 0.9984803473534374 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 153, 'max_depth': 6, 'learning_rate': 0.010235757899384974, 'subsample': 0.5078851320210707, 'colsample_bytree': 0.895030137129993, 'reg_alpha': 0.03861220242594292, 'reg_lambda': 0.02212494326607424}. Best is trial 10 with value: 1.0.\n",
      "[I 2025-04-17 22:04:30,369] Trial 12 finished with value: 0.999083954045809 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 153, 'max_depth': 6, 'learning_rate': 0.025623973208335857, 'subsample': 0.507774004022916, 'colsample_bytree': 0.8976510340302623, 'reg_alpha': 0.03486225998009837, 'reg_lambda': 0.023186584064837486}. Best is trial 10 with value: 1.0.\n",
      "[I 2025-04-17 22:04:33,814] Trial 13 finished with value: 1.0 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 159, 'max_depth': 6, 'learning_rate': 0.027607687549237887, 'subsample': 0.5043079704444401, 'colsample_bytree': 0.8978784026717374, 'reg_alpha': 0.02374560424514677, 'reg_lambda': 0.02835742981739364}. Best is trial 10 with value: 1.0.\n",
      "[I 2025-04-17 22:04:37,494] Trial 14 finished with value: 0.999388761640445 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 176, 'max_depth': 6, 'learning_rate': 0.02503804306361425, 'subsample': 0.5669580382412186, 'colsample_bytree': 0.8578795428933839, 'reg_alpha': 0.018761987272488283, 'reg_lambda': 0.035991443594139985}. Best is trial 10 with value: 1.0.\n",
      "[I 2025-04-17 22:04:39,802] Trial 15 finished with value: 0.9960095143122618 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 135, 'max_depth': 5, 'learning_rate': 0.02211743246550621, 'subsample': 0.5426286843804776, 'colsample_bytree': 0.7373059514582306, 'reg_alpha': 0.018490203915840032, 'reg_lambda': 0.005509265771644425}. Best is trial 10 with value: 1.0.\n",
      "[I 2025-04-17 22:04:41,907] Trial 16 finished with value: 0.9981616175067038 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 174, 'max_depth': 4, 'learning_rate': 0.04219830215787254, 'subsample': 0.6562355967884571, 'colsample_bytree': 0.8529432496488337, 'reg_alpha': 0.04694785749801882, 'reg_lambda': 0.03951233014405553}. Best is trial 10 with value: 1.0.\n",
      "[I 2025-04-17 22:04:44,475] Trial 17 finished with value: 0.9869895261961231 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 129, 'max_depth': 6, 'learning_rate': 0.07223582016805108, 'subsample': 0.5042064825553925, 'colsample_bytree': 0.531434482158471, 'reg_alpha': 0.022500288185157737, 'reg_lambda': 0.018780949943550986}. Best is trial 10 with value: 1.0.\n",
      "[I 2025-04-17 22:04:47,054] Trial 18 finished with value: 0.999386122587452 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 234, 'max_depth': 4, 'learning_rate': 0.021001194702648513, 'subsample': 0.6496717156435869, 'colsample_bytree': 0.7524796001700633, 'reg_alpha': 0.04910594210517795, 'reg_lambda': 0.07228926189720793}. Best is trial 10 with value: 1.0.\n",
      "[I 2025-04-17 22:04:49,873] Trial 19 finished with value: 0.999690756910622 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 196, 'max_depth': 5, 'learning_rate': 0.032784199839239414, 'subsample': 0.5452007515723605, 'colsample_bytree': 0.8998046931277964, 'reg_alpha': 0.024342363163433453, 'reg_lambda': 0.012959938515651595}. Best is trial 10 with value: 1.0.\n",
      "[I 2025-04-17 22:04:52,281] Trial 20 finished with value: 0.9978585375589732 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 103, 'max_depth': 6, 'learning_rate': 0.04543736700309209, 'subsample': 0.6153583025278428, 'colsample_bytree': 0.8397244751980825, 'reg_alpha': 0.010522583664842794, 'reg_lambda': 0.04248442945788283}. Best is trial 10 with value: 1.0.\n",
      "[I 2025-04-17 22:04:55,108] Trial 21 finished with value: 0.998772958463596 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.031240195636828803, 'subsample': 0.5404218158899602, 'colsample_bytree': 0.8910586176385501, 'reg_alpha': 0.02628743147036499, 'reg_lambda': 0.010621219739899466}. Best is trial 10 with value: 1.0.\n",
      "[I 2025-04-17 22:04:57,657] Trial 22 finished with value: 0.9996934500875657 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 164, 'max_depth': 5, 'learning_rate': 0.018714958658214285, 'subsample': 0.5413228653422889, 'colsample_bytree': 0.8707986840937636, 'reg_alpha': 0.028876485247068498, 'reg_lambda': 0.026701271724728734}. Best is trial 10 with value: 1.0.\n",
      "[I 2025-04-17 22:05:01,231] Trial 23 finished with value: 0.9996936151179693 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 165, 'max_depth': 6, 'learning_rate': 0.018518298528205447, 'subsample': 0.5021480708066327, 'colsample_bytree': 0.8627524766661936, 'reg_alpha': 0.04207246383171933, 'reg_lambda': 0.030348040263739343}. Best is trial 10 with value: 1.0.\n",
      "[I 2025-04-17 22:05:04,285] Trial 24 finished with value: 0.9990828485224477 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 134, 'max_depth': 6, 'learning_rate': 0.01692738016859851, 'subsample': 0.5001104380552115, 'colsample_bytree': 0.8246893941521904, 'reg_alpha': 0.04147785351187869, 'reg_lambda': 0.04242510316125739}. Best is trial 10 with value: 1.0.\n",
      "[I 2025-04-17 22:05:07,694] Trial 25 finished with value: 0.999079518551067 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 161, 'max_depth': 6, 'learning_rate': 0.02853802138243719, 'subsample': 0.5754458416741375, 'colsample_bytree': 0.785551218972542, 'reg_alpha': 0.05429599533648098, 'reg_lambda': 0.030107369019989835}. Best is trial 10 with value: 1.0.\n",
      "[I 2025-04-17 22:05:10,546] Trial 26 finished with value: 0.9975475685537176 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 122, 'max_depth': 6, 'learning_rate': 0.03786242145963227, 'subsample': 0.5314974551980955, 'colsample_bytree': 0.8667444716419868, 'reg_alpha': 0.04403828146755911, 'reg_lambda': 0.04753224864288079}. Best is trial 10 with value: 1.0.\n",
      "[I 2025-04-17 22:05:13,250] Trial 27 finished with value: 0.9910748096354046 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 142, 'max_depth': 5, 'learning_rate': 0.01581052255791922, 'subsample': 0.5986056694310699, 'colsample_bytree': 0.6310149108431516, 'reg_alpha': 0.03222212769416082, 'reg_lambda': 0.014373022492372954}. Best is trial 10 with value: 1.0.\n",
      "[I 2025-04-17 22:05:17,845] Trial 28 finished with value: 0.9944522959895181 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 217, 'max_depth': 6, 'learning_rate': 0.09342423313174963, 'subsample': 0.7508084454737263, 'colsample_bytree': 0.8263018101378827, 'reg_alpha': 0.08169851694680827, 'reg_lambda': 0.07064996659335776}. Best is trial 10 with value: 1.0.\n",
      "[I 2025-04-17 22:05:21,159] Trial 29 finished with value: 0.9996925074694826 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 208, 'max_depth': 5, 'learning_rate': 0.015850840813497497, 'subsample': 0.7949729709665475, 'colsample_bytree': 0.865838023381612, 'reg_alpha': 0.013700423653586168, 'reg_lambda': 0.0015950231157159656}. Best is trial 10 with value: 1.0.\n",
      "[I 2025-04-17 22:05:21,160] A new study created in memory with name: no-name-5e95600e-bd7e-4169-99a3-b6ab2ce18dac\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters:\n",
      "{'objective': 'reg:squarederror', 'n_estimators': 153, 'max_depth': 6, 'learning_rate': 0.013769795623498312, 'subsample': 0.5036259961123959, 'colsample_bytree': 0.8990403873185487, 'reg_alpha': 0.03718980808445292, 'reg_lambda': 0.02905102865197595}\n",
      "Best Quadratic Kappa: 1.0000\n",
      "Starting optimization for LGBM with 30 trials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-17 22:05:25,597] Trial 0 finished with value: 0.999086783692646 and parameters: {'objective': 'tweedie', 'n_estimators': 264, 'max_depth': 6, 'learning_rate': 0.042108703182399225, 'subsample': 0.8807326778859068, 'colsample_bytree': 0.8268314891460407, 'min_child_samples': 77, 'tweedie_variance_power': 1.1007983721478802}. Best is trial 0 with value: 0.999086783692646.\n",
      "[I 2025-04-17 22:05:28,952] Trial 1 finished with value: 0.996944676066996 and parameters: {'objective': 'tweedie', 'n_estimators': 295, 'max_depth': 4, 'learning_rate': 0.03213793447305246, 'subsample': 0.6249670102548569, 'colsample_bytree': 0.6866324679858986, 'min_child_samples': 10, 'tweedie_variance_power': 1.8917917994050568}. Best is trial 0 with value: 0.999086783692646.\n",
      "[I 2025-04-17 22:05:30,285] Trial 2 finished with value: 0.9956929789103881 and parameters: {'objective': 'tweedie', 'n_estimators': 111, 'max_depth': 3, 'learning_rate': 0.0421330553061845, 'subsample': 0.7787679978934577, 'colsample_bytree': 0.6891879888440918, 'min_child_samples': 22, 'tweedie_variance_power': 1.4151043103605343}. Best is trial 0 with value: 0.999086783692646.\n",
      "[I 2025-04-17 22:05:34,531] Trial 3 finished with value: 0.9863843125024641 and parameters: {'objective': 'regression', 'n_estimators': 266, 'max_depth': 5, 'learning_rate': 0.05417262394723984, 'subsample': 0.8256207603639049, 'colsample_bytree': 0.5481687827719213, 'min_child_samples': 30}. Best is trial 0 with value: 0.999086783692646.\n",
      "[I 2025-04-17 22:05:40,528] Trial 4 finished with value: 0.9972481148175818 and parameters: {'objective': 'tweedie', 'n_estimators': 282, 'max_depth': 6, 'learning_rate': 0.09008722258162104, 'subsample': 0.669667440702564, 'colsample_bytree': 0.6008191437200602, 'min_child_samples': 31, 'tweedie_variance_power': 1.20004652237192}. Best is trial 0 with value: 0.999086783692646.\n",
      "[I 2025-04-17 22:05:41,775] Trial 5 finished with value: 0.999086783692646 and parameters: {'objective': 'regression', 'n_estimators': 213, 'max_depth': 2, 'learning_rate': 0.04194391046482268, 'subsample': 0.8312613797992308, 'colsample_bytree': 0.810545215423479, 'min_child_samples': 42}. Best is trial 0 with value: 0.999086783692646.\n",
      "[I 2025-04-17 22:05:46,186] Trial 6 finished with value: 0.999690756910622 and parameters: {'objective': 'poisson', 'n_estimators': 201, 'max_depth': 6, 'learning_rate': 0.08636427693081034, 'subsample': 0.7886973921073616, 'colsample_bytree': 0.891452897563926, 'min_child_samples': 43}. Best is trial 6 with value: 0.999690756910622.\n",
      "[I 2025-04-17 22:05:52,113] Trial 7 finished with value: 0.9984966425000797 and parameters: {'objective': 'poisson', 'n_estimators': 214, 'max_depth': 6, 'learning_rate': 0.06229872945678891, 'subsample': 0.6244693347885025, 'colsample_bytree': 0.8047031027337487, 'min_child_samples': 13}. Best is trial 6 with value: 0.999690756910622.\n",
      "[I 2025-04-17 22:05:55,754] Trial 8 finished with value: 0.9993832643801046 and parameters: {'objective': 'regression', 'n_estimators': 219, 'max_depth': 5, 'learning_rate': 0.06486740023903041, 'subsample': 0.7245317664148946, 'colsample_bytree': 0.6985538548924377, 'min_child_samples': 21}. Best is trial 6 with value: 0.999690756910622.\n",
      "[I 2025-04-17 22:05:57,643] Trial 9 finished with value: 0.9960475958243291 and parameters: {'objective': 'tweedie', 'n_estimators': 208, 'max_depth': 3, 'learning_rate': 0.025683851330569586, 'subsample': 0.6218127424612724, 'colsample_bytree': 0.7243691806922692, 'min_child_samples': 70, 'tweedie_variance_power': 1.6481214766333872}. Best is trial 6 with value: 0.999690756910622.\n",
      "[I 2025-04-17 22:06:00,179] Trial 10 finished with value: 0.9984993356770234 and parameters: {'objective': 'poisson', 'n_estimators': 143, 'max_depth': 5, 'learning_rate': 0.09860622324794249, 'subsample': 0.5279358400991598, 'colsample_bytree': 0.8479880878659092, 'min_child_samples': 99}. Best is trial 6 with value: 0.999690756910622.\n",
      "[I 2025-04-17 22:06:02,534] Trial 11 finished with value: 0.9984807708726805 and parameters: {'objective': 'regression', 'n_estimators': 166, 'max_depth': 5, 'learning_rate': 0.07907388259977068, 'subsample': 0.7366479655464446, 'colsample_bytree': 0.8911747909249872, 'min_child_samples': 49}. Best is trial 6 with value: 0.999690756910622.\n",
      "[I 2025-04-17 22:06:06,459] Trial 12 finished with value: 0.9972692355232763 and parameters: {'objective': 'poisson', 'n_estimators': 235, 'max_depth': 5, 'learning_rate': 0.07546216514032163, 'subsample': 0.7270789566217738, 'colsample_bytree': 0.7374566344668808, 'min_child_samples': 59}. Best is trial 6 with value: 0.999690756910622.\n",
      "[I 2025-04-17 22:06:09,033] Trial 13 finished with value: 0.9905004445536525 and parameters: {'objective': 'poisson', 'n_estimators': 168, 'max_depth': 4, 'learning_rate': 0.06899245158848366, 'subsample': 0.7776660512915837, 'colsample_bytree': 0.6259443426973056, 'min_child_samples': 39}. Best is trial 6 with value: 0.999690756910622.\n",
      "[I 2025-04-17 22:06:12,059] Trial 14 finished with value: 0.999086783692646 and parameters: {'objective': 'regression', 'n_estimators': 181, 'max_depth': 6, 'learning_rate': 0.08133112143304275, 'subsample': 0.6977784533262832, 'colsample_bytree': 0.760765277208602, 'min_child_samples': 58}. Best is trial 6 with value: 0.999690756910622.\n",
      "[I 2025-04-17 22:06:16,846] Trial 15 finished with value: 0.9812168070451103 and parameters: {'objective': 'poisson', 'n_estimators': 241, 'max_depth': 5, 'learning_rate': 0.013040284703366711, 'subsample': 0.7784804038062508, 'colsample_bytree': 0.6514000642376636, 'min_child_samples': 22}. Best is trial 6 with value: 0.999690756910622.\n",
      "[I 2025-04-17 22:06:21,306] Trial 16 finished with value: 0.9844899700071817 and parameters: {'objective': 'regression', 'n_estimators': 237, 'max_depth': 6, 'learning_rate': 0.05921867289354235, 'subsample': 0.8994664703420135, 'colsample_bytree': 0.5034726849171556, 'min_child_samples': 36}. Best is trial 6 with value: 0.999690756910622.\n",
      "[I 2025-04-17 22:06:23,292] Trial 17 finished with value: 0.9987775406032681 and parameters: {'objective': 'regression', 'n_estimators': 191, 'max_depth': 4, 'learning_rate': 0.09249356660693335, 'subsample': 0.5176108016540337, 'colsample_bytree': 0.8901827294142888, 'min_child_samples': 50}. Best is trial 6 with value: 0.999690756910622.\n",
      "[I 2025-04-17 22:06:26,775] Trial 18 finished with value: 0.99908306280721 and parameters: {'objective': 'poisson', 'n_estimators': 146, 'max_depth': 5, 'learning_rate': 0.07014087412300452, 'subsample': 0.8323543471622682, 'colsample_bytree': 0.7781484238494021, 'min_child_samples': 22}. Best is trial 6 with value: 0.999690756910622.\n",
      "[I 2025-04-17 22:06:28,660] Trial 19 finished with value: 0.992939805532625 and parameters: {'objective': 'regression', 'n_estimators': 227, 'max_depth': 3, 'learning_rate': 0.08687369563303934, 'subsample': 0.6617290545977299, 'colsample_bytree': 0.5919544921286991, 'min_child_samples': 68}. Best is trial 6 with value: 0.999690756910622.\n",
      "[I 2025-04-17 22:06:30,830] Trial 20 finished with value: 0.9914747786540377 and parameters: {'objective': 'poisson', 'n_estimators': 104, 'max_depth': 6, 'learning_rate': 0.05235539715273843, 'subsample': 0.5757649968780674, 'colsample_bytree': 0.6641038832484525, 'min_child_samples': 87}. Best is trial 6 with value: 0.999690756910622.\n",
      "[I 2025-04-17 22:06:34,849] Trial 21 finished with value: 0.9993870110815843 and parameters: {'objective': 'tweedie', 'n_estimators': 259, 'max_depth': 6, 'learning_rate': 0.04603748532360525, 'subsample': 0.8996615145584601, 'colsample_bytree': 0.8593519014446747, 'min_child_samples': 78, 'tweedie_variance_power': 1.0254489702575833}. Best is trial 6 with value: 0.999690756910622.\n",
      "[I 2025-04-17 22:06:38,373] Trial 22 finished with value: 0.9984966425000797 and parameters: {'objective': 'tweedie', 'n_estimators': 247, 'max_depth': 6, 'learning_rate': 0.048053361015055106, 'subsample': 0.8626598320875719, 'colsample_bytree': 0.8505353691231685, 'min_child_samples': 91, 'tweedie_variance_power': 1.0099144190012457}. Best is trial 6 with value: 0.999690756910622.\n",
      "[I 2025-04-17 22:06:42,011] Trial 23 finished with value: 0.9993870110815843 and parameters: {'objective': 'tweedie', 'n_estimators': 268, 'max_depth': 5, 'learning_rate': 0.06437690954536228, 'subsample': 0.7472833300945694, 'colsample_bytree': 0.8658201093260551, 'min_child_samples': 79, 'tweedie_variance_power': 1.41014608309154}. Best is trial 6 with value: 0.999690756910622.\n",
      "[I 2025-04-17 22:06:46,386] Trial 24 finished with value: 0.99908306280721 and parameters: {'objective': 'tweedie', 'n_estimators': 263, 'max_depth': 6, 'learning_rate': 0.03443350240319921, 'subsample': 0.7650013475439331, 'colsample_bytree': 0.8673080999913659, 'min_child_samples': 78, 'tweedie_variance_power': 1.3855101712841953}. Best is trial 6 with value: 0.999690756910622.\n",
      "[I 2025-04-17 22:06:50,368] Trial 25 finished with value: 0.999086783692646 and parameters: {'objective': 'tweedie', 'n_estimators': 293, 'max_depth': 5, 'learning_rate': 0.07348911777007813, 'subsample': 0.8133103874102852, 'colsample_bytree': 0.8956664180952649, 'min_child_samples': 67, 'tweedie_variance_power': 1.6459045937542633}. Best is trial 6 with value: 0.999690756910622.\n",
      "[I 2025-04-17 22:06:54,182] Trial 26 finished with value: 0.999086783692646 and parameters: {'objective': 'tweedie', 'n_estimators': 253, 'max_depth': 6, 'learning_rate': 0.08366570480911213, 'subsample': 0.8594995398496332, 'colsample_bytree': 0.837330106508805, 'min_child_samples': 81, 'tweedie_variance_power': 1.2533054148981877}. Best is trial 6 with value: 0.999690756910622.\n",
      "[I 2025-04-17 22:06:57,291] Trial 27 finished with value: 0.999690756910622 and parameters: {'objective': 'tweedie', 'n_estimators': 279, 'max_depth': 4, 'learning_rate': 0.017009292614329926, 'subsample': 0.8107038021081387, 'colsample_bytree': 0.7986917384913343, 'min_child_samples': 100, 'tweedie_variance_power': 1.6183606852216421}. Best is trial 6 with value: 0.999690756910622.\n",
      "[I 2025-04-17 22:07:00,393] Trial 28 finished with value: 0.9993777929358079 and parameters: {'objective': 'tweedie', 'n_estimators': 282, 'max_depth': 4, 'learning_rate': 0.015199577268347503, 'subsample': 0.8055777198521059, 'colsample_bytree': 0.7861050460714823, 'min_child_samples': 97, 'tweedie_variance_power': 1.6766390235974429}. Best is trial 6 with value: 0.999690756910622.\n",
      "[I 2025-04-17 22:07:02,082] Trial 29 finished with value: 0.9938335595750878 and parameters: {'objective': 'tweedie', 'n_estimators': 278, 'max_depth': 2, 'learning_rate': 0.01994652149519958, 'subsample': 0.8739104942035663, 'colsample_bytree': 0.8201947877379528, 'min_child_samples': 87, 'tweedie_variance_power': 1.88949172071284}. Best is trial 6 with value: 0.999690756910622.\n",
      "[I 2025-04-17 22:07:02,083] A new study created in memory with name: no-name-acda2441-7306-4df8-897e-ce54b8853a55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters:\n",
      "{'objective': 'poisson', 'n_estimators': 201, 'max_depth': 6, 'learning_rate': 0.08636427693081034, 'subsample': 0.7886973921073616, 'colsample_bytree': 0.891452897563926, 'min_child_samples': 43}\n",
      "Best Quadratic Kappa: 0.9997\n",
      "Starting optimization for CATBOOST with 30 trials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-17 22:07:05,454] Trial 0 finished with value: 0.9721850009712185 and parameters: {'objective': 'reg:tweedie', 'n_estimators': 201, 'max_depth': 2, 'learning_rate': 0.05758940192305538, 'subsample': 0.7769602622748815, 'colsample_bytree': 0.585462333511136, 'reg_alpha': 0.062355738541679716, 'reg_lambda': 0.05734873000379019, 'tweedie_variance_power': 1.9387442553489547}. Best is trial 0 with value: 0.9721850009712185.\n",
      "[I 2025-04-17 22:07:08,354] Trial 1 finished with value: 0.9883269915910129 and parameters: {'objective': 'reg:tweedie', 'n_estimators': 103, 'max_depth': 5, 'learning_rate': 0.06094165459596609, 'subsample': 0.5781175500659781, 'colsample_bytree': 0.7121289425757289, 'reg_alpha': 0.038879631183110455, 'reg_lambda': 0.07301627235587334, 'tweedie_variance_power': 1.3902673927154106}. Best is trial 1 with value: 0.9883269915910129.\n",
      "[I 2025-04-17 22:07:11,990] Trial 2 finished with value: 0.9855409516396618 and parameters: {'objective': 'reg:tweedie', 'n_estimators': 185, 'max_depth': 3, 'learning_rate': 0.06006440823652438, 'subsample': 0.5912099854579127, 'colsample_bytree': 0.678955058020332, 'reg_alpha': 0.023602662543223442, 'reg_lambda': 0.08988086930750278, 'tweedie_variance_power': 1.2090248113481086}. Best is trial 1 with value: 0.9883269915910129.\n",
      "[I 2025-04-17 22:07:13,840] Trial 3 finished with value: 0.9886285786979826 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 213, 'max_depth': 3, 'learning_rate': 0.09915366867237994, 'subsample': 0.7854216415600728, 'colsample_bytree': 0.6060596779875459, 'reg_alpha': 0.06549794072077683, 'reg_lambda': 0.015418771677114373}. Best is trial 3 with value: 0.9886285786979826.\n",
      "[I 2025-04-17 22:07:15,746] Trial 4 finished with value: 0.998473985593041 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 221, 'max_depth': 3, 'learning_rate': 0.016527858690580887, 'subsample': 0.7703608617393214, 'colsample_bytree': 0.7749125979902922, 'reg_alpha': 0.08004307363869602, 'reg_lambda': 0.04334100418568679}. Best is trial 4 with value: 0.998473985593041.\n",
      "[I 2025-04-17 22:07:19,327] Trial 5 finished with value: 0.9971439394343156 and parameters: {'objective': 'reg:tweedie', 'n_estimators': 134, 'max_depth': 5, 'learning_rate': 0.01307455092888264, 'subsample': 0.7156269031264282, 'colsample_bytree': 0.8028952800383649, 'reg_alpha': 0.044549694013381255, 'reg_lambda': 0.04608806761611629, 'tweedie_variance_power': 1.5451229816817453}. Best is trial 4 with value: 0.998473985593041.\n",
      "[I 2025-04-17 22:07:21,108] Trial 6 finished with value: 0.9969254286510031 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 133, 'max_depth': 4, 'learning_rate': 0.05646338809964227, 'subsample': 0.8647547717213547, 'colsample_bytree': 0.8118263482831948, 'reg_alpha': 0.03396223767409615, 'reg_lambda': 0.09252402166632878}. Best is trial 4 with value: 0.998473985593041.\n",
      "[I 2025-04-17 22:07:26,910] Trial 7 finished with value: 0.9945029221894597 and parameters: {'objective': 'reg:tweedie', 'n_estimators': 220, 'max_depth': 5, 'learning_rate': 0.038332619201101474, 'subsample': 0.7460126253028405, 'colsample_bytree': 0.7819857958565938, 'reg_alpha': 0.09786089911173258, 'reg_lambda': 0.04879973111899228, 'tweedie_variance_power': 1.5347868045434319}. Best is trial 4 with value: 0.998473985593041.\n",
      "[I 2025-04-17 22:07:28,997] Trial 8 finished with value: 0.9855632389754618 and parameters: {'objective': 'reg:tweedie', 'n_estimators': 107, 'max_depth': 2, 'learning_rate': 0.06557113978731664, 'subsample': 0.544385271431744, 'colsample_bytree': 0.8043978948539775, 'reg_alpha': 0.04238232641176021, 'reg_lambda': 0.09599614038298257, 'tweedie_variance_power': 1.8737083406608606}. Best is trial 4 with value: 0.998473985593041.\n",
      "[I 2025-04-17 22:07:32,288] Trial 9 finished with value: 0.999690756910622 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 242, 'max_depth': 5, 'learning_rate': 0.06213483770199067, 'subsample': 0.6361432398499731, 'colsample_bytree': 0.8984098508224246, 'reg_alpha': 0.08073052380885518, 'reg_lambda': 0.050299349056725534}. Best is trial 9 with value: 0.999690756910622.\n",
      "[I 2025-04-17 22:07:37,574] Trial 10 finished with value: 0.993846268487206 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 296, 'max_depth': 6, 'learning_rate': 0.08785522934428112, 'subsample': 0.6466997701083416, 'colsample_bytree': 0.8713874040480786, 'reg_alpha': 0.0032555193281699688, 'reg_lambda': 0.018046307127620398}. Best is trial 9 with value: 0.999690756910622.\n",
      "[I 2025-04-17 22:07:40,198] Trial 11 finished with value: 1.0 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 262, 'max_depth': 4, 'learning_rate': 0.03266711907186448, 'subsample': 0.6480198149422716, 'colsample_bytree': 0.898523689014005, 'reg_alpha': 0.09266144837373504, 'reg_lambda': 0.0316571095313497}. Best is trial 11 with value: 1.0.\n",
      "[I 2025-04-17 22:07:42,965] Trial 12 finished with value: 0.9990794001517571 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 274, 'max_depth': 4, 'learning_rate': 0.03988659313870301, 'subsample': 0.6641649857325376, 'colsample_bytree': 0.8912521152019637, 'reg_alpha': 0.09982492222294742, 'reg_lambda': 0.026289935254387248}. Best is trial 11 with value: 1.0.\n",
      "[I 2025-04-17 22:07:47,509] Trial 13 finished with value: 0.9984660817479123 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 254, 'max_depth': 6, 'learning_rate': 0.036300236754245374, 'subsample': 0.5088521108175694, 'colsample_bytree': 0.8961703527978507, 'reg_alpha': 0.08261571843262754, 'reg_lambda': 0.0006520368992076267}. Best is trial 11 with value: 1.0.\n",
      "[I 2025-04-17 22:07:51,013] Trial 14 finished with value: 0.9879558887382422 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 252, 'max_depth': 5, 'learning_rate': 0.07712685270628933, 'subsample': 0.6448522978224599, 'colsample_bytree': 0.5040141113913162, 'reg_alpha': 0.07908293273468739, 'reg_lambda': 0.032866648123100195}. Best is trial 11 with value: 1.0.\n",
      "[I 2025-04-17 22:07:54,100] Trial 15 finished with value: 0.9981689400703779 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 242, 'max_depth': 4, 'learning_rate': 0.030028312325979648, 'subsample': 0.613211916601824, 'colsample_bytree': 0.839950005333471, 'reg_alpha': 0.0632170953561537, 'reg_lambda': 0.06489952711352687}. Best is trial 11 with value: 1.0.\n",
      "[I 2025-04-17 22:07:59,419] Trial 16 finished with value: 0.9941571109314646 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 295, 'max_depth': 6, 'learning_rate': 0.04664375083793443, 'subsample': 0.6939394150020807, 'colsample_bytree': 0.7219012396947899, 'reg_alpha': 0.08846268079367196, 'reg_lambda': 0.07538470424961113}. Best is trial 11 with value: 1.0.\n",
      "[I 2025-04-17 22:08:02,144] Trial 17 finished with value: 0.9981584160122257 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 172, 'max_depth': 5, 'learning_rate': 0.07471445090545706, 'subsample': 0.6989465133375462, 'colsample_bytree': 0.852957457589558, 'reg_alpha': 0.07014772685349913, 'reg_lambda': 0.03674656833916372}. Best is trial 11 with value: 1.0.\n",
      "[I 2025-04-17 22:08:04,994] Trial 18 finished with value: 0.9963079842037219 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 272, 'max_depth': 4, 'learning_rate': 0.022991476437038146, 'subsample': 0.8495420226242997, 'colsample_bytree': 0.7460016195529089, 'reg_alpha': 0.05510788752828942, 'reg_lambda': 0.05727633700611852}. Best is trial 11 with value: 1.0.\n",
      "[I 2025-04-17 22:08:07,213] Trial 19 finished with value: 0.9926208230032924 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 238, 'max_depth': 3, 'learning_rate': 0.04622228606757929, 'subsample': 0.6191988026109659, 'colsample_bytree': 0.6503047009469498, 'reg_alpha': 0.09036334525745535, 'reg_lambda': 0.003923802915278211}. Best is trial 11 with value: 1.0.\n",
      "[I 2025-04-17 22:08:10,105] Trial 20 finished with value: 0.9969232204236274 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 272, 'max_depth': 4, 'learning_rate': 0.07142712487624661, 'subsample': 0.5628909961259047, 'colsample_bytree': 0.8407052363685625, 'reg_alpha': 0.07270258536337967, 'reg_lambda': 0.025608344770819493}. Best is trial 11 with value: 1.0.\n",
      "[I 2025-04-17 22:08:13,037] Trial 21 finished with value: 1.0 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 270, 'max_depth': 4, 'learning_rate': 0.04533077379408988, 'subsample': 0.6648092902230389, 'colsample_bytree': 0.8978736824649602, 'reg_alpha': 0.09694018344149191, 'reg_lambda': 0.03079528674530784}. Best is trial 11 with value: 1.0.\n",
      "[I 2025-04-17 22:08:15,916] Trial 22 finished with value: 0.9984534687523212 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 265, 'max_depth': 4, 'learning_rate': 0.048574323810770946, 'subsample': 0.6688976529679996, 'colsample_bytree': 0.8954770127607751, 'reg_alpha': 0.09127794800075897, 'reg_lambda': 0.03521256729396482}. Best is trial 11 with value: 1.0.\n",
      "[I 2025-04-17 22:08:19,131] Trial 23 finished with value: 0.9984667551808833 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 232, 'max_depth': 5, 'learning_rate': 0.027892446844112885, 'subsample': 0.6158844808229595, 'colsample_bytree': 0.8491560545427915, 'reg_alpha': 0.09989134609198587, 'reg_lambda': 0.014165550679359068}. Best is trial 11 with value: 1.0.\n",
      "[I 2025-04-17 22:08:21,536] Trial 24 finished with value: 0.99846530164366 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 287, 'max_depth': 3, 'learning_rate': 0.03199717304386046, 'subsample': 0.7284207552541978, 'colsample_bytree': 0.8669638503049635, 'reg_alpha': 0.08679948086378529, 'reg_lambda': 0.026375354795240728}. Best is trial 11 with value: 1.0.\n",
      "[I 2025-04-17 22:08:24,236] Trial 25 finished with value: 0.998762210739857 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 259, 'max_depth': 4, 'learning_rate': 0.048810872910910234, 'subsample': 0.6817313123659848, 'colsample_bytree': 0.829159275851671, 'reg_alpha': 0.07385156604746149, 'reg_lambda': 0.03862578397744144}. Best is trial 11 with value: 1.0.\n",
      "[I 2025-04-17 22:08:27,495] Trial 26 finished with value: 1.0 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 246, 'max_depth': 5, 'learning_rate': 0.020345146384211695, 'subsample': 0.635126144356417, 'colsample_bytree': 0.8992075851258204, 'reg_alpha': 0.09372909158021701, 'reg_lambda': 0.054763771414695184}. Best is trial 11 with value: 1.0.\n",
      "[I 2025-04-17 22:08:30,172] Trial 27 finished with value: 0.9990809844194499 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 279, 'max_depth': 4, 'learning_rate': 0.020819822803972526, 'subsample': 0.8255250553625495, 'colsample_bytree': 0.7745912511784719, 'reg_alpha': 0.09289687498540408, 'reg_lambda': 0.059039015552914964}. Best is trial 11 with value: 1.0.\n",
      "[I 2025-04-17 22:08:33,637] Trial 28 finished with value: 0.9987761450787922 and parameters: {'objective': 'reg:squarederror', 'n_estimators': 186, 'max_depth': 6, 'learning_rate': 0.02246609951117283, 'subsample': 0.5301517702537624, 'colsample_bytree': 0.8673080782585685, 'reg_alpha': 0.05652463753739601, 'reg_lambda': 0.009701546802098643}. Best is trial 11 with value: 1.0.\n",
      "[I 2025-04-17 22:08:38,404] Trial 29 finished with value: 0.9789603532687225 and parameters: {'objective': 'reg:tweedie', 'n_estimators': 201, 'max_depth': 5, 'learning_rate': 0.013597325483952209, 'subsample': 0.584659183346721, 'colsample_bytree': 0.5071359679932124, 'reg_alpha': 0.023195389418817925, 'reg_lambda': 0.05466116272092592, 'tweedie_variance_power': 1.0117693388237838}. Best is trial 11 with value: 1.0.\n",
      "[I 2025-04-17 22:08:38,405] A new study created in memory with name: no-name-1e185b77-591c-471f-aa11-42fc0b1dc1a9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters:\n",
      "{'objective': 'reg:squarederror', 'n_estimators': 262, 'max_depth': 4, 'learning_rate': 0.03266711907186448, 'subsample': 0.6480198149422716, 'colsample_bytree': 0.898523689014005, 'reg_alpha': 0.09266144837373504, 'reg_lambda': 0.0316571095313497}\n",
      "Best Quadratic Kappa: 1.0000\n",
      "Starting optimization for EXTRATREES with 30 trials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-17 22:08:39,964] Trial 0 finished with value: 0.9444645693546713 and parameters: {'n_estimators': 162, 'max_depth': 20, 'min_samples_leaf': 10, 'max_features': 'log2', 'bootstrap': False}. Best is trial 0 with value: 0.9444645693546713.\n",
      "[I 2025-04-17 22:08:43,051] Trial 1 finished with value: 0.9444310673447591 and parameters: {'n_estimators': 388, 'max_depth': 27, 'min_samples_leaf': 20, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 0 with value: 0.9444645693546713.\n",
      "[I 2025-04-17 22:08:48,522] Trial 2 finished with value: 0.9625581051277796 and parameters: {'n_estimators': 372, 'max_depth': 30, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 2 with value: 0.9625581051277796.\n",
      "[I 2025-04-17 22:09:04,410] Trial 3 finished with value: 0.9996888323819114 and parameters: {'n_estimators': 266, 'max_depth': 27, 'min_samples_leaf': 2, 'max_features': None, 'bootstrap': False}. Best is trial 3 with value: 0.9996888323819114.\n",
      "[I 2025-04-17 22:09:19,068] Trial 4 finished with value: 1.0 and parameters: {'n_estimators': 362, 'max_depth': 23, 'min_samples_leaf': 3, 'max_features': None, 'bootstrap': True}. Best is trial 4 with value: 1.0.\n",
      "[I 2025-04-17 22:09:21,673] Trial 5 finished with value: 0.9513602551432216 and parameters: {'n_estimators': 275, 'max_depth': 16, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': False}. Best is trial 4 with value: 1.0.\n",
      "[I 2025-04-17 22:09:23,244] Trial 6 finished with value: 0.9462162331503066 and parameters: {'n_estimators': 156, 'max_depth': 14, 'min_samples_leaf': 19, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 4 with value: 1.0.\n",
      "[I 2025-04-17 22:09:31,094] Trial 7 finished with value: 0.9987609612828386 and parameters: {'n_estimators': 222, 'max_depth': 6, 'min_samples_leaf': 14, 'max_features': None, 'bootstrap': False}. Best is trial 4 with value: 1.0.\n",
      "[I 2025-04-17 22:09:32,558] Trial 8 finished with value: 0.9479701266648835 and parameters: {'n_estimators': 153, 'max_depth': 17, 'min_samples_leaf': 12, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 4 with value: 1.0.\n",
      "[I 2025-04-17 22:09:35,578] Trial 9 finished with value: 0.9460464976707591 and parameters: {'n_estimators': 435, 'max_depth': 20, 'min_samples_leaf': 12, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 4 with value: 1.0.\n",
      "[I 2025-04-17 22:09:51,528] Trial 10 finished with value: 0.9996870360251858 and parameters: {'n_estimators': 498, 'max_depth': 8, 'min_samples_leaf': 7, 'max_features': None, 'bootstrap': True}. Best is trial 4 with value: 1.0.\n",
      "[I 2025-04-17 22:10:04,999] Trial 11 finished with value: 0.9996962541709624 and parameters: {'n_estimators': 299, 'max_depth': 25, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}. Best is trial 4 with value: 1.0.\n",
      "[I 2025-04-17 22:10:20,239] Trial 12 finished with value: 0.9996962541709624 and parameters: {'n_estimators': 341, 'max_depth': 23, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': True}. Best is trial 4 with value: 1.0.\n",
      "[I 2025-04-17 22:10:32,303] Trial 13 finished with value: 1.0 and parameters: {'n_estimators': 320, 'max_depth': 24, 'min_samples_leaf': 5, 'max_features': None, 'bootstrap': True}. Best is trial 4 with value: 1.0.\n",
      "[I 2025-04-17 22:10:48,113] Trial 14 finished with value: 0.9996870360251858 and parameters: {'n_estimators': 440, 'max_depth': 22, 'min_samples_leaf': 6, 'max_features': None, 'bootstrap': True}. Best is trial 4 with value: 1.0.\n",
      "[I 2025-04-17 22:10:56,245] Trial 15 finished with value: 1.0 and parameters: {'n_estimators': 227, 'max_depth': 12, 'min_samples_leaf': 8, 'max_features': None, 'bootstrap': True}. Best is trial 4 with value: 1.0.\n",
      "[I 2025-04-17 22:11:09,105] Trial 16 finished with value: 0.9996940792877137 and parameters: {'n_estimators': 343, 'max_depth': 29, 'min_samples_leaf': 5, 'max_features': None, 'bootstrap': True}. Best is trial 4 with value: 1.0.\n",
      "[I 2025-04-17 22:11:12,130] Trial 17 finished with value: 0.9550593223189263 and parameters: {'n_estimators': 412, 'max_depth': 23, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True}. Best is trial 4 with value: 1.0.\n",
      "[I 2025-04-17 22:11:23,262] Trial 18 finished with value: 0.9990731596288358 and parameters: {'n_estimators': 330, 'max_depth': 20, 'min_samples_leaf': 9, 'max_features': None, 'bootstrap': True}. Best is trial 4 with value: 1.0.\n",
      "[I 2025-04-17 22:11:41,555] Trial 19 finished with value: 0.9996940792877137 and parameters: {'n_estimators': 472, 'max_depth': 26, 'min_samples_leaf': 4, 'max_features': None, 'bootstrap': True}. Best is trial 4 with value: 1.0.\n",
      "[I 2025-04-17 22:11:43,226] Trial 20 finished with value: 0.9360439111540193 and parameters: {'n_estimators': 227, 'max_depth': 12, 'min_samples_leaf': 15, 'max_features': 'log2', 'bootstrap': True}. Best is trial 4 with value: 1.0.\n",
      "[I 2025-04-17 22:11:47,191] Trial 21 finished with value: 0.9993832901961482 and parameters: {'n_estimators': 102, 'max_depth': 11, 'min_samples_leaf': 8, 'max_features': None, 'bootstrap': True}. Best is trial 4 with value: 1.0.\n",
      "[I 2025-04-17 22:11:55,587] Trial 22 finished with value: 1.0 and parameters: {'n_estimators': 232, 'max_depth': 11, 'min_samples_leaf': 7, 'max_features': None, 'bootstrap': True}. Best is trial 4 with value: 1.0.\n",
      "[I 2025-04-17 22:12:08,233] Trial 23 finished with value: 1.0 and parameters: {'n_estimators': 308, 'max_depth': 14, 'min_samples_leaf': 3, 'max_features': None, 'bootstrap': True}. Best is trial 4 with value: 1.0.\n",
      "[I 2025-04-17 22:12:15,137] Trial 24 finished with value: 0.9996870360251858 and parameters: {'n_estimators': 194, 'max_depth': 18, 'min_samples_leaf': 8, 'max_features': None, 'bootstrap': True}. Best is trial 4 with value: 1.0.\n",
      "[I 2025-04-17 22:12:24,976] Trial 25 finished with value: 0.9993880028418151 and parameters: {'n_estimators': 267, 'max_depth': 24, 'min_samples_leaf': 6, 'max_features': None, 'bootstrap': True}. Best is trial 4 with value: 1.0.\n",
      "[I 2025-04-17 22:12:38,036] Trial 26 finished with value: 0.9993880028418151 and parameters: {'n_estimators': 375, 'max_depth': 8, 'min_samples_leaf': 3, 'max_features': None, 'bootstrap': True}. Best is trial 4 with value: 1.0.\n",
      "[I 2025-04-17 22:12:47,711] Trial 27 finished with value: 0.9993804861127515 and parameters: {'n_estimators': 301, 'max_depth': 21, 'min_samples_leaf': 11, 'max_features': None, 'bootstrap': True}. Best is trial 4 with value: 1.0.\n",
      "[I 2025-04-17 22:12:50,033] Trial 28 finished with value: 0.9452414319577521 and parameters: {'n_estimators': 356, 'max_depth': 18, 'min_samples_leaf': 9, 'max_features': 'log2', 'bootstrap': True}. Best is trial 4 with value: 1.0.\n",
      "[I 2025-04-17 22:12:56,624] Trial 29 finished with value: 0.9996870360251858 and parameters: {'n_estimators': 191, 'max_depth': 15, 'min_samples_leaf': 10, 'max_features': None, 'bootstrap': True}. Best is trial 4 with value: 1.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters:\n",
      "{'n_estimators': 362, 'max_depth': 23, 'min_samples_leaf': 3, 'max_features': None, 'bootstrap': True}\n",
      "Best Quadratic Kappa: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# For XGBoost\n",
    "XGB_OPTIMAL_PARAMS = run_optuna_optimization(X, Y_target, Y_class, model_type='xgb', splitter=splitter, apply_weighting=True, n_trials=30)\n",
    "\n",
    "# For LightGBM\n",
    "LGBM_OPTIMAL_PARAMS = run_optuna_optimization(X, Y_target, Y_class, model_type='lgbm', splitter=splitter, apply_weighting=True, n_trials=30)\n",
    "\n",
    "# For CatBoost\n",
    "CATBOOST_OPTIMAL_PARAMS = run_optuna_optimization(X, Y_target, Y_class, model_type='catboost', splitter=splitter, apply_weighting=True, n_trials=30)\n",
    "\n",
    "# For ExtraTree\n",
    "XTRATREE_OPTIMAL_PARAMS = run_optuna_optimization(X, Y_target, Y_class, model_type='extratrees', splitter=splitter, apply_weighting=True, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LGBMRegressor, Parameters: {'objective': 'poisson', 'n_estimators': 201, 'max_depth': 6, 'learning_rate': 0.08636427693081034, 'subsample': 0.7886973921073616, 'colsample_bytree': 0.891452897563926, 'min_child_samples': 43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] The number of features in data (127) is not the same as it was in training data (165).\n",
      "You can set ``predict_disable_shape_check=true`` to discard this error, but please be aware what you are doing.\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "The number of features in data (127) is not the same as it was in training data (165).\nYou can set ``predict_disable_shape_check=true`` to discard this error, but please be aware what you are doing.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLightGBMError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m model_instance.fit(X, Y_target, sample_weight=weights)\n\u001b[32m     21\u001b[39m thresholds_ens = np.mean(thresholds, axis=\u001b[32m0\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m predictions = \u001b[43mmodel_instance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m predictions = convert_to_categories(predictions, thresholds_ens)\n\u001b[32m     24\u001b[39m predictions_list.append(predictions)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NTU/Y4/SC4000/Child-Mind-Institute-Problematic-Internet-Use/mlenv/lib/python3.12/site-packages/lightgbm/sklearn.py:1144\u001b[39m, in \u001b[36mLGBMModel.predict\u001b[39m\u001b[34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, validate_features, **kwargs)\u001b[39m\n\u001b[32m   1141\u001b[39m predict_params = _choose_param_value(\u001b[33m\"\u001b[39m\u001b[33mnum_threads\u001b[39m\u001b[33m\"\u001b[39m, predict_params, \u001b[38;5;28mself\u001b[39m.n_jobs)\n\u001b[32m   1142\u001b[39m predict_params[\u001b[33m\"\u001b[39m\u001b[33mnum_threads\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m._process_n_jobs(predict_params[\u001b[33m\"\u001b[39m\u001b[33mnum_threads\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m1144\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_Booster\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[union-attr]\u001b[39;49;00m\n\u001b[32m   1145\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1146\u001b[39m \u001b[43m    \u001b[49m\u001b[43mraw_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraw_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1147\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpred_leaf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpred_leaf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpred_contrib\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpred_contrib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpredict_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NTU/Y4/SC4000/Child-Mind-Institute-Problematic-Internet-Use/mlenv/lib/python3.12/site-packages/lightgbm/basic.py:4767\u001b[39m, in \u001b[36mBooster.predict\u001b[39m\u001b[34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, validate_features, **kwargs)\u001b[39m\n\u001b[32m   4765\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4766\u001b[39m         num_iteration = -\u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m4767\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpredictor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4768\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4769\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4770\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4771\u001b[39m \u001b[43m    \u001b[49m\u001b[43mraw_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraw_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4772\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpred_leaf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpred_leaf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4773\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpred_contrib\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpred_contrib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4774\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_has_header\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_has_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4775\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4776\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NTU/Y4/SC4000/Child-Mind-Institute-Problematic-Internet-Use/mlenv/lib/python3.12/site-packages/lightgbm/basic.py:1204\u001b[39m, in \u001b[36m_InnerPredictor.predict\u001b[39m\u001b[34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, validate_features)\u001b[39m\n\u001b[32m   1197\u001b[39m     preds, nrow = \u001b[38;5;28mself\u001b[39m.__pred_for_csc(\n\u001b[32m   1198\u001b[39m         csc=data,\n\u001b[32m   1199\u001b[39m         start_iteration=start_iteration,\n\u001b[32m   1200\u001b[39m         num_iteration=num_iteration,\n\u001b[32m   1201\u001b[39m         predict_type=predict_type,\n\u001b[32m   1202\u001b[39m     )\n\u001b[32m   1203\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, np.ndarray):\n\u001b[32m-> \u001b[39m\u001b[32m1204\u001b[39m     preds, nrow = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pred_for_np2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1205\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmat\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1206\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1207\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1208\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1209\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m _is_pyarrow_table(data):\n\u001b[32m   1211\u001b[39m     preds, nrow = \u001b[38;5;28mself\u001b[39m.__pred_for_pyarrow_table(\n\u001b[32m   1212\u001b[39m         table=data,\n\u001b[32m   1213\u001b[39m         start_iteration=start_iteration,\n\u001b[32m   1214\u001b[39m         num_iteration=num_iteration,\n\u001b[32m   1215\u001b[39m         predict_type=predict_type,\n\u001b[32m   1216\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NTU/Y4/SC4000/Child-Mind-Institute-Problematic-Internet-Use/mlenv/lib/python3.12/site-packages/lightgbm/basic.py:1361\u001b[39m, in \u001b[36m_InnerPredictor.__pred_for_np2d\u001b[39m\u001b[34m(self, mat, start_iteration, num_iteration, predict_type)\u001b[39m\n\u001b[32m   1359\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m preds, nrow\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1361\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__inner_predict_np2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1362\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmat\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1363\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1364\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1365\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1366\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1367\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NTU/Y4/SC4000/Child-Mind-Institute-Problematic-Internet-Use/mlenv/lib/python3.12/site-packages/lightgbm/basic.py:1307\u001b[39m, in \u001b[36m_InnerPredictor.__inner_predict_np2d\u001b[39m\u001b[34m(self, mat, start_iteration, num_iteration, predict_type, preds)\u001b[39m\n\u001b[32m   1305\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mWrong length of pre-allocated predict array\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1306\u001b[39m out_num_preds = ctypes.c_int64(\u001b[32m0\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1307\u001b[39m \u001b[43m_safe_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1308\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLGBM_BoosterPredictForMat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1309\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1310\u001b[39m \u001b[43m        \u001b[49m\u001b[43mptr_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1311\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtype_ptr_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1312\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int32\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1313\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int32\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1314\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1315\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1316\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1318\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_c_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpred_parameter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1319\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_num_preds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1320\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPOINTER\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_double\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1321\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1322\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_preds != out_num_preds.value:\n\u001b[32m   1324\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mWrong length for predict results\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NTU/Y4/SC4000/Child-Mind-Institute-Problematic-Internet-Use/mlenv/lib/python3.12/site-packages/lightgbm/basic.py:313\u001b[39m, in \u001b[36m_safe_call\u001b[39m\u001b[34m(ret)\u001b[39m\n\u001b[32m    305\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Check the return value from C API call.\u001b[39;00m\n\u001b[32m    306\u001b[39m \n\u001b[32m    307\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    310\u001b[39m \u001b[33;03m    The return value from C API calls.\u001b[39;00m\n\u001b[32m    311\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret != \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(_LIB.LGBM_GetLastError().decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[31mLightGBMError\u001b[39m: The number of features in data (127) is not the same as it was in training data (165).\nYou can set ``predict_disable_shape_check=true`` to discard this error, but please be aware what you are doing."
     ]
    }
   ],
   "source": [
    "model_param_combination = [\n",
    "    [LGBMRegressor, LGBM_OPTIMAL_PARAMS],\n",
    "    [XGBRegressor, XGB_OPTIMAL_PARAMS],\n",
    "    [ExtraTreesRegressor, XTRATREE_OPTIMAL_PARAMS],\n",
    "    [CatBoostRegressor, CATBOOST_OPTIMAL_PARAMS],\n",
    "]\n",
    "train_list = []\n",
    "predictions_list = []\n",
    "score_list = []\n",
    "weights = sample_weights_optimized(train['PCIAT-PCIAT_Total'])\n",
    "test = test.drop(columns=['id', 'BIA-BIA_BMI', 'SDS-SDS_Total_T'])\n",
    "\n",
    "for model,params in model_param_combination:\n",
    "    print(f\"Model: {model.__name__}, Parameters: {params}\")\n",
    "    model_instance = model(**params)\n",
    "    kappa_score, oof, thresholds = evaluate_k_fold_validate(\n",
    "        model_instance, X, Y_target, Y_class, splitter, apply_weighting=True)\n",
    "    score_list.append(kappa_score)\n",
    "\n",
    "    model_instance.fit(X, Y_target, sample_weight=weights)\n",
    "    thresholds_ens = np.mean(thresholds, axis=0)\n",
    "    predictions = model_instance.predict(test)\n",
    "    predictions = convert_to_categories(predictions, thresholds_ens)\n",
    "    predictions_list.append(predictions)\n",
    "    train_pred = model_instance.predict(X)\n",
    "    train_pred = convert_to_categories(train_pred, thresholds_ens)\n",
    "    train_list.append(train_pred)\n",
    "\n",
    "ENSEMBLE = 'voting'\n",
    "if ENSEMBLE == 'voting':\n",
    "    # Mode voting (majority rules)\n",
    "    test_preds = np.array(predictions_list)\n",
    "    voted_test = stats.mode(test_preds, axis=0).mode.flatten().astype(int)\n",
    "    final_test = voted_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "submission = pd.read_csv(\"/kaggle/input/child-mind-institute-problematic-internet-use/sample_submission.csv\")\n",
    "submission['sii'] = final_test\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
